{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy as copy\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "def seed_torch(seed=1122):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "BERT_PATH = 'bert-base-chinese/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetBERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GetBERT, self).__init__()\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(\"chinese-bert-wwm-ext\")\n",
    "        self.bert = BertModel.from_pretrained(\"chinese-bert-wwm-ext\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, sentence_lists):\n",
    "        \"\"\"\n",
    "        输入句子列表(去掉了停用词的)\n",
    "        \"\"\"\n",
    "        sentence_lists = [' '.join(x) for x in sentence_lists]\n",
    "        # print('sentence_lists:'+str(sentence_lists))\n",
    "        ids = self.bert_tokenizer(sentence_lists, padding=True, return_tensors=\"pt\")\n",
    "        # print('ids:'+str(ids))\n",
    "        inputs = ids['input_ids']\n",
    "        # print('inputs:'+str(inputs))\n",
    "\n",
    "        embeddings = self.bert(inputs)\n",
    "        # print(str(embeddings[0].shape))\n",
    "        x = embeddings[0]  # 1 * 768\n",
    "        # print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pre:\n",
    "    def __init__(self, text):\n",
    "        \"\"\"\n",
    "        输入一个文本\n",
    "        \"\"\"\n",
    "        self.puncs_coarse = ['。', '!', '；', '？', '……', '\\n', ' ']\n",
    "        self.text = text\n",
    "        self.stopwords = self.deal_wrap('dict/stop1205.txt')\n",
    "\n",
    "    def segment(self, sentence):\n",
    "        sentence_seged = jieba.cut(sentence.strip())\n",
    "        outstr = ''\n",
    "        for word in sentence_seged:\n",
    "            if word not in self.stopwords:\n",
    "                if word != '\\t':\n",
    "                    outstr += word\n",
    "                    outstr += \" \"\n",
    "        word_list = outstr.split(' ')\n",
    "        pattern = '[A-Za-z]*[0-9]*[\\'\\\"\\%.\\s\\@\\!\\#\\$\\^\\&\\*\\(\\)\\-\\<\\>\\?\\/\\,\\~\\`\\:\\;]*[：；”“ ‘’+-——！，。？、~@#￥%……&*（）【】]*'\n",
    "        t = [re.sub(pattern, \"\", x.strip()) for x in word_list]\n",
    "        t = [x for x in t if x != '']\n",
    "        return ''.join(t)\n",
    "\n",
    "    def deal_wrap(self, filedict):\n",
    "        temp = []\n",
    "        for x in open(filedict, 'r', encoding='utf-8').readlines():\n",
    "            temp.append(x.strip())\n",
    "        return temp\n",
    "\n",
    "    def split_sentence_coarse(self):\n",
    "        \"\"\"\n",
    "        按照。！？“”等中文完整句子语义来分句\n",
    "        1. 去除换行符、多余的空格、百分号\n",
    "        2. 分句，存入列表\n",
    "        :return:装着每个句子的列表（包括标点符号）\n",
    "        \"\"\"\n",
    "\n",
    "        text = self.text\n",
    "        sentences = []\n",
    "        start = 0\n",
    "        for i in range(len(text)):\n",
    "            if text[i] in self.puncs_coarse:\n",
    "                sentences.append(text[start:i + 1])\n",
    "                start = i + 1\n",
    "        if start == 0:\n",
    "            sentences.append(text)\n",
    "        return sentences\n",
    "\n",
    "    def get_keywords(self, data):\n",
    "        \"\"\"\n",
    "        如果句子太长，就进行关键词提取\n",
    "        \"\"\"\n",
    "        from jieba import analyse\n",
    "        textrank = analyse.textrank\n",
    "        keywords = textrank(data, topK=8)\n",
    "        return ''.join(keywords)\n",
    "\n",
    "    def preprocess(self):\n",
    "        # 分句\n",
    "        sentences = self.split_sentence_coarse()\n",
    "        # 对每个句子，去除里面的停用词，再连起来\n",
    "        # 对每个句子，如果句子太长，长度大于20（我随便定的），就抽取八个关键词连起来\n",
    "        new_sent = []\n",
    "        for i in sentences:\n",
    "            if len(i) < 5:\n",
    "                new_sent.append(i)\n",
    "                continue\n",
    "            i = self.segment(i)\n",
    "            if len(i) > 25:\n",
    "                i = self.get_keywords(i)\n",
    "            if i != '':\n",
    "                new_sent.append(i)\n",
    "        return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData():\n",
    "    def __init__(self, pos=5000, neg=4600):\n",
    "        data = pd.read_csv('sentiment_classify_data/raw_comment_v2.csv')\n",
    "        data = data[data['score'] != 3].reset_index()\n",
    "        data['label'] = data['score'].map(lambda a: 1 if a in [4, 5] else 0)\n",
    "        data.drop(['post_time','score','shop_url'],inplace=True,axis=1)\n",
    "        \n",
    "#         data = pd.read_excel('sentiment_classify_data/comments_raw_v1.xls')\n",
    "#         data = data[data['score'] != 3].reset_index()\n",
    "#         data['label'] = data['score'].map(lambda a: 1 if a in [4, 5] else 0)\n",
    "#         data.drop(['id', 'score'], inplace=True, axis=1)\n",
    "        \n",
    "        data['content'] = [str(i) for i in list(data['content'])]\n",
    "        # 原数据标签为0（负向情感）的数据有3632条，正向情感的有57262条\n",
    "        data1 = data[data['label'] == 1].sample(pos)\n",
    "        data0 = data[data['label'] == 0].sample(neg)\n",
    "        data = pd.concat([data1, data0], axis=0, ignore_index=True)\n",
    "        self.data = data\n",
    "\n",
    "    def split_sen(self):\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(self.data)):\n",
    "            p = Pre(self.data['content'][i])\n",
    "            sen_lst = p.preprocess()\n",
    "            if sen_lst == []:\n",
    "                continue\n",
    "            x.append(sen_lst)\n",
    "            y.append(self.data['label'][i])\n",
    "        print(len(x))\n",
    "        print(y.count(1))\n",
    "        print(y.count(0))\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm_layer = nn.LSTM(input_size=768, hidden_size=128, batch_first=True)\n",
    "        self.linear_layer = nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, (h_n, h_c) = self.lstm_layer(x)\n",
    "        a, b, c = h_n.shape\n",
    "        out = self.linear_layer(h_n.reshape(a * b, c))\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch, train_dataLoader, test_dataLoader):\n",
    "    # 训练模型\n",
    "    best_model = None\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    best_loss = 100\n",
    "    epoch_cnt = 0\n",
    "    for _ in range(epoch):\n",
    "        total_train_loss = 0\n",
    "        total_train_num = 0\n",
    "        total_test_loss = 0\n",
    "        total_test_num = 0\n",
    "        for x, y in tqdm(train_dataLoader,\n",
    "                         desc='Epoch: {}| Train Loss: {}| Test Loss: {}'.format(_, train_loss, test_loss)):\n",
    "        #for x, y in train_dataLoader:\n",
    "            x_num = len(x)\n",
    "            p = model(x)\n",
    "            loss = loss_func(p, y.long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_num += x_num\n",
    "        train_loss = total_train_loss / total_train_num\n",
    "        train_loss_list.append(train_loss)\n",
    "        for x, y in test_dataLoader:\n",
    "            x_num = len(x)\n",
    "            p = model(x)\n",
    "            loss = loss_func(p, y.long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            total_test_loss += loss.item()\n",
    "            total_test_num += x_num\n",
    "        test_loss = total_test_loss / total_test_num\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "        # early stop\n",
    "        if best_loss > test_loss:\n",
    "            best_loss = test_loss\n",
    "            best_model = copy(model)\n",
    "            torch.save(best_model.state_dict(), 'lstm_.pth')\n",
    "            epoch_cnt = 0\n",
    "        else:\n",
    "            epoch_cnt += 1\n",
    "            \n",
    "        if epoch_cnt > early_stop:\n",
    "            torch.save(best_model.state_dict(), 'lstm_.pth')\n",
    "            print(\"保存模型\")\n",
    "            #print(best_model.state_dict())\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataLoader_):\n",
    "    pred = []\n",
    "    label = []\n",
    "    model_.load_state_dict(torch.load(\"lstm_.pth\"))\n",
    "    model_.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_num = 0\n",
    "    for x, y in test_dataLoader_:\n",
    "        x_num = len(x)\n",
    "        p = model_(x)\n",
    "        #         print('##', len(p), len(y))\n",
    "        loss = loss_func(p, y.long())\n",
    "        total_test_loss += loss.item()\n",
    "        total_test_num += x_num\n",
    "        pred.extend(p.data.squeeze(1).tolist())\n",
    "        label.extend(y.tolist())\n",
    "    test_loss = total_test_loss / total_test_num\n",
    "    # print('##', len(pred), len(label))\n",
    "    return pred, label, test_loss, test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9574\n",
      "4988\n",
      "4586\n",
      "训练集有8616个数据\n",
      "测试集有958个数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train Loss: 0| Test Loss: 0: 100%|██████████| 431/431 [01:33<00:00,  4.59it/s]\n",
      "Epoch: 1| Train Loss: 0.008397677536919208| Test Loss: 0.09006156385069351: 100%|██████████| 431/431 [01:30<00:00,  4.75it/s]\n",
      "Epoch: 2| Train Loss: 0.018091594061434627| Test Loss: 0.07377149405770611: 100%|██████████| 431/431 [01:31<00:00,  4.69it/s]\n",
      "Epoch: 3| Train Loss: 0.020521014404786663| Test Loss: 0.06546261002910411: 100%|██████████| 431/431 [01:34<00:00,  4.55it/s]\n",
      "Epoch: 4| Train Loss: 0.020582437517853002| Test Loss: 0.06717363057467535: 100%|██████████| 431/431 [01:31<00:00,  4.70it/s]\n",
      "Epoch: 5| Train Loss: 0.021161091505716743| Test Loss: 0.06410236625556906: 100%|██████████| 431/431 [01:32<00:00,  4.67it/s]\n",
      "Epoch: 6| Train Loss: 0.02217739091679357| Test Loss: 0.06274305691549822: 100%|██████████| 431/431 [01:32<00:00,  4.65it/s]\n",
      "Epoch: 7| Train Loss: 0.02250584140558318| Test Loss: 0.062374300212601284: 100%|██████████| 431/431 [01:26<00:00,  4.97it/s]\n",
      "Epoch: 8| Train Loss: 0.022654985062978614| Test Loss: 0.06207982092971344: 100%|██████████| 431/431 [01:18<00:00,  5.48it/s]\n",
      "Epoch: 9| Train Loss: 0.022746062227900977| Test Loss: 0.061936836604161154: 100%|██████████| 431/431 [01:24<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5271398747390397\n"
     ]
    }
   ],
   "source": [
    "seed_torch(22)\n",
    "epoch = 10\n",
    "batch_size = 20\n",
    "early_stop = 5\n",
    "test_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "# 初始化模型\n",
    "model = LSTM()\n",
    "model_ = LSTM()\n",
    "\n",
    "# 数据处理部分\n",
    "gd = GetData()\n",
    "x, y = gd.split_sen()\n",
    "pos = y.count(1)\n",
    "neg = y.count(0)\n",
    "pos_train = int(pos*0.9)\n",
    "neg_train = int(neg*0.9)\n",
    "x1 = x[:pos]  # 3988   --- 3589train 399test\n",
    "y1 = y[:pos]\n",
    "x0 = x[pos:]  # 3589   ---- 3230train 359test\n",
    "y0 = y[pos:]\n",
    "\n",
    "train_x = x0[:neg_train] + x1[:pos_train]\n",
    "train_y = y0[:neg_train] + y1[:pos_train]\n",
    "print(\"训练集有\"+str(len(train_x))+\"个数据\")\n",
    "\n",
    "# c = list(zip(train_x, train_y))\n",
    "# random.shuffle(c)\n",
    "# c = random.sample(c, 50)\n",
    "# train_x[:], train_y[:] = zip(*c)\n",
    "\n",
    "test_x = x0[neg_train:] + x1[pos_train:]\n",
    "test_y = y0[neg_train:] + y1[pos_train:]\n",
    "print(\"测试集有\"+str(len(test_x))+\"个数据\")\n",
    "\n",
    "bert = GetBERT()\n",
    "x_train = bert(train_x)\n",
    "x_test = bert(test_x)\n",
    "y_train = torch.tensor(train_y).float()\n",
    "y_test = torch.tensor(test_y).float()\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_dataLoader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_dataLoader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(epoch, train_dataLoader, test_dataLoader)\n",
    "p, y, test_loss, test_loss_list = test_model(test_dataLoader)\n",
    "ans = []\n",
    "for t in p:\n",
    "    if t[0]>t[1]:\n",
    "        ans.append(0)\n",
    "    else:\n",
    "        ans.append(1)\n",
    "print(accuracy_score(ans,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n",
      "10.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())   # --> 0\n",
    "print(torch.cuda.is_available())   # --> False\n",
    "print(torch.version.cuda)          # --> 9.0.176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fef4375e070>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEOCAYAAAC0BAELAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYX0lEQVR4nO3debBedZ3n8fcXEgkRJmQDgWu8URhNAi3LZWvGKWgIJDokuAyiUmZs29ilTvW0IxIGZbVngHZrym2iUkNryTJYtnGIAwGJUA4qNxFbwuINgW5uwhogihAQ+M4fzwk+PDzZ7n1+z5K8X1WnnnN+53fO/f64RT73LM85kZlIktRqu3S6AEnSjsmAkSQVYcBIkoowYCRJRRgwkqQixnS6gG4yZcqU7O/v73QZktRTVqxY8XhmTm1sN2Dq9Pf3Mzg42OkyJKmnRMS/NGv3FJkkqQgDRpJUhAEjSSrCazCSNAp//OMfGR4eZuPGjZ0upbhx48bR19fH2LFjt6m/ASNJozA8PMyee+5Jf38/EdHpcorJTNavX8/w8DDTp0/fpm08RSZJo7Bx40YmT568Q4cLQEQwefLk7TpSM2AkaZR29HDZZHvHacBIkoowYCSphz311FN87WtfG9G2X/7yl3nmmWdaXNGfGDCS1MO6OWC8i0ySetiiRYu47777OOSQQ5g9ezZ7770311xzDc899xzvfOc7ueCCC/jDH/7AaaedxvDwMC+++CKf/exneeSRR1i3bh3HH388U6ZM4eabb255bQaMJLXIBT9axV3rftfSfc7c799w3imzNrv+4osv5s477+SOO+7ghhtu4Nprr+WXv/wlmcm8efO45ZZbeOyxx9hvv/247rrrANiwYQMTJkzgi1/8IjfffDNTpkxpac2beIpMknYQN9xwAzfccAOHHnoohx12GPfccw9DQ0McfPDBLFu2jLPOOotbb72VCRMmtKUej2AkqUW2dKTRDpnJ2WefzUc/+tFXrVu5ciVLly7lM5/5DCeccALnnntu8Xo8gpGkHrbnnnvy+9//HoCTTz6Zyy+/nKeffhqAtWvX8uijj7Ju3TrGjx/PGWecwZlnnsnKlStftW0JHsFIUg+bPHkyxx57LAcddBBz587l/e9/P8cccwwAe+yxB9/97ndZvXo1Z555Jrvssgtjx47l61//OgALFy5kzpw57LfffkUu8kdmtnynvWpgYCB94Zik7XH33XczY8aMTpfRNs3GGxErMnOgsa+nyCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkaQeNtKnKb/97W/nqaeean1BdQwYSephmwuYF154YYvbLV26lL322qtQVTVdHTARMSci7o2I1RGxqMn63SLi6mr9LyKiv2H9tIh4OiI+1baiJamN6h/Xf8QRR/C2t72NefPmMXPmTABOPfVUDj/8cGbNmsXixYtf3q6/v5/HH3+cBx54gBkzZvCRj3yEWbNmcdJJJ/Hss8+2pLaufVRMROwKfBWYDQwDt0fEksy8q67bh4EnM/OAiDgduAR4b936LwI/blfNknZyP14ED/+mtft83cEw9+LNrq5/XP/y5ct5xzvewZ133sn06dMBuPzyy5k0aRLPPvssRxxxBO9+97uZPHnyK/YxNDTElVdeyTe/+U1OO+00vv/973PGGWeMuvRuPoI5ElidmWsy83ngKmB+Q5/5wBXV/LXACRERABFxKnA/sKo95UpS5x155JEvhwvAZZddxlvf+laOPvpoHnzwQYaGhl61zfTp0znkkEMAOPzww3nggQdaUkvXHsEA+wMP1i0PA0dtrk9mvhARG4DJEbEROIva0c8WT49FxEJgIcC0adNaU7mkndMWjjTa5bWvfe3L88uXL+fGG2/ktttuY/z48Rx33HFs3LjxVdvstttuL8/vuuuuLTtF1s1HMKNxPvClzHx6ax0zc3FmDmTmwNSpU8tXJkkttKVH7m/YsIGJEycyfvx47rnnHn7+85+3tbZuPoJZC7y+brmvamvWZzgixgATgPXUjnTeExGXAnsBL0XExsz8SvGqJamN6h/Xv/vuu7PPPvu8vG7OnDl84xvfYMaMGbz5zW/m6KOPbmttXfu4/iowfgucQC1Ibgfen5mr6vp8HDg4M/+6usj/rsw8rWE/5wNPZ+bnt/YzfVy/pO3l4/o3/7j+rj2Cqa6pfAK4HtgVuDwzV0XEhcBgZi4Bvg18JyJWA08Ap3euYklSva4NGIDMXAosbWg7t25+I/Aft7KP84sUJ0naoh31Ir8ktU23Xmpote0dpwEjSaMwbtw41q9fv8OHTGayfv16xo0bt83bdPUpMknqdn19fQwPD/PYY491upTixo0bR19f3zb3N2AkaRTGjh37im/O6088RSZJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQV0dUBExFzIuLeiFgdEYuarN8tIq6u1v8iIvqr9tkRsSIiflN9/kXbi5eknVzXBkxE7Ap8FZgLzATeFxEzG7p9GHgyMw8AvgRcUrU/DpySmQcDC4DvtKdqSdImXRswwJHA6sxck5nPA1cB8xv6zAeuqOavBU6IiMjMX2Xmuqp9FbB7ROzWlqolSUB3B8z+wIN1y8NVW9M+mfkCsAGY3NDn3cDKzHyuUJ2SpCbGdLqAkiJiFrXTZidtoc9CYCHAtGnT2lSZJO34uvkIZi3w+rrlvqqtaZ+IGANMANZXy33AD4APZuZ9m/shmbk4Mwcyc2Dq1KktLF+Sdm7dHDC3AwdGxPSIeA1wOrCkoc8SahfxAd4D/CQzMyL2Aq4DFmXmz9pVsCTpT7o2YKprKp8ArgfuBq7JzFURcWFEzKu6fRuYHBGrgU8Cm25l/gRwAHBuRNxRTXu3eQiStFOLzOx0DV1jYGAgBwcHO12GJPWUiFiRmQON7V17BCNJ6m0GjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklTEmFbsJCLGAPOBScCPMvPhVuxXktS7tvsIJiIujYjb65YDuBG4BvifwG8i4k2tK1GS1ItGcopsDnBr3fIpwL8H/h54f9W2aJR1SZJ63EhOkb0eGKpbPgW4PzMXAUTELOADLahNktTDRnIE8xrghbrl46mdIttkDbDvaIqSJPW+kQTMg8Ax8PLRyhuBn9at3xt4evSlSZJ62UhOkV0FfDYi9gZmAb8DltatPxS4rwW1SZJ62EiOYP4H8L+oHcUk8MHMfAogIiYA84CbWlSfJKlHbfcRTGY+B3y4mhr9ntr1l2dGWZckqce15IuWdcZm5oYW71OS1ING8kXLuRFxfkPbxyLid8AfIuJ7ETG2VQVKknrTSK7BnAm8ZdNCRMwA/gFYBywD3gt8vCXVSZJ61kgCZgYwWLf8XuBZ4MjMnAtcDSxoQW1ExJyIuDciVkfEq54OEBG7RcTV1fpfRER/3bqzq/Z7I+LkVtQjSdp2IwmYicDjdcsnAj/JzN9Vy8uB6aOsi4jYFfgqMBeYCbwvImY2dPsw8GRmHgB8Cbik2nYmcDq126jnAF+r9idJapORBMzjwBsAImJP4Ahe+WyysUAr/jE/ElidmWsy83lq37+Z39BnPnBFNX8tcEL18M35wFWZ+Vxm3g+srvYnSWqTkdxFdhvw1xGxitrRxRjgx3XrDwAeakFt+1N7asAmw8BRm+uTmS9ExAZgctX+84Zt92/2QyJiIbAQYNq0aS0oW5IEIzuCOa/a7hrgQ8A/ZuZd8PKj+98J/KxlFRaWmYszcyAzB6ZOndrpciRphzGSL1reVd05diywITNvqVu9F7VrIctbUNtaak9u3qSvamvWZ7h66dkEYP02bitJKmhEr0zOzCcy80cN4UJmPpmZ/5CZv25BbbcDB0bE9Ih4DbWL9ksa+izhT3esvYfazQZZtZ9e3WU2HTgQ+GULapIkbaMRf5O/emvlfGpPU4baY/p/mJktedBldU3lE8D11G4auDwzV0XEhcBgZi4Bvg18JyJWA09QCyGqftcAd1F7tcDHM/PFVtQlSdo2UfuDfzs3iriI2lsrG+8Wewn475l5bgtqa7uBgYEcHBzcekdJ0ssiYkVmDjS2j+RRMX8JnAP8AjiV2umnA6v524BzIuI/jaJWSdIOYCSnyD5OLVyOy8z6N1veFxFLqX0n5j9Te6S/JGknNdJHxVzVEC5A7boJtS9EzhhtYZKk3jaSgHke2GML6/es+kiSdmIjCZjbgY9GxD6NK6rXKC+kdgpNkrQTG8k1mIuovRL57oj4NrVbgaH2YMkPUTuC+UBrypMk9aqRfJP/loh4F/AV4L82rP5X4IOZeeurt5Qk7UxG+k3+H1F7JP9R1L7ceDq1pxW/EeiLiLu2sLkkaScw4m/yZ+ZL1K7H3F7fHhFTgDePsi5JUo8b0RGMJElbY8BIkoowYCRJRRgwkqQitukif0R8cjv2eewIa5Ek7UC29S6yz2/nfrf/HQCSpB3KtgbM8UWrkCTtcLYpYDLzp6ULkSTtWLzIL0kqwoCRJBVhwEiSijBgJElFGDCSpCIMGElSEQaMJKkIA0aSVIQBI0kqwoCRJBVhwEiSijBgJElFGDCSpCK6MmAiYlJELIuIoepz4mb6Laj6DEXEgqptfERcFxH3RMSqiLi4vdVLkqBLAwZYBNyUmQcCN1XLrxARk4DzgKOAI4Hz6oLo85n5FuBQ4NiImNuesiVJm3RrwMwHrqjmrwBObdLnZGBZZj6RmU8Cy4A5mflMZt4MkJnPAyuBvvIlS5LqdWvA7JOZD1XzDwP7NOmzP/Bg3fJw1fayiNgLOIXaUZAkqY229ZXJLRcRNwKva7LqnPqFzMyIyBHsfwxwJXBZZq7ZQr+FwEKAadOmbe+PkSRtRscCJjNP3Ny6iHgkIvbNzIciYl/g0Sbd1gLH1S33AcvrlhcDQ5n55a3Usbjqy8DAwHYHmSSpuW49RbYEWFDNLwB+2KTP9cBJETGxurh/UtVGRHwOmAD8l/KlSpKa6daAuRiYHRFDwInVMhExEBHfAsjMJ4CLgNur6cLMfCIi+qidZpsJrIyIOyLirzoxCEnamUWmZ4U2GRgYyMHBwU6XIUk9JSJWZOZAY3u3HsFIknqcASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkSQVYcBIkoowYCRJRRgwkqQiDBhJUhFdGTARMSkilkXEUPU5cTP9FlR9hiJiQZP1SyLizvIVS5IadWXAAIuAmzLzQOCmavkVImIScB5wFHAkcF59EEXEu4Cn21OuJKlRtwbMfOCKav4K4NQmfU4GlmXmE5n5JLAMmAMQEXsAnwQ+V75USVIz3Row+2TmQ9X8w8A+TfrsDzxYtzxctQFcBHwBeGZrPygiFkbEYEQMPvbYY6MoWZJUb0ynfnBE3Ai8rsmqc+oXMjMjIrdjv4cAb8rMv42I/q31z8zFwGKAgYGBbf45kqQt61jAZOaJm1sXEY9ExL6Z+VBE7As82qTbWuC4uuU+YDlwDDAQEQ9QG9/eEbE8M49DktQ23XqKbAmw6a6wBcAPm/S5HjgpIiZWF/dPAq7PzK9n5n6Z2Q/8O+C3hosktV+3BszFwOyIGAJOrJaJiIGI+BZAZj5B7VrL7dV0YdUmSeoCkellh00GBgZycHCw02VIUk+JiBWZOdDY3q1HMJKkHmfASJKKMGAkSUUYMJKkIgwYSVIRBowkqQgDRpJUhAEjSSrCgJEkFWHASJKKMGAkSUUYMJKkIgwYSVIRBowkqQgDRpJUhAEjSSrCgJEkFWHASJKKMGAkSUUYMJKkIgwYSVIRBowkqQgDRpJUhAEjSSoiMrPTNXSNiHgM+JdO17GdpgCPd7qINnPMOwfH3DvekJlTGxsNmB4XEYOZOdDpOtrJMe8cHHPv8xSZJKkIA0aSVIQB0/sWd7qADnDMOwfH3OO8BiNJKsIjGElSEQaMJKkIA6YHRMSkiFgWEUPV58TN9FtQ9RmKiAVN1i+JiDvLVzx6oxlzRIyPiOsi4p6IWBURF7e3+u0TEXMi4t6IWB0Ri5qs3y0irq7W/yIi+uvWnV213xsRJ7e18FEY6ZgjYnZErIiI31Sff9H24kdgNL/jav20iHg6Ij7VtqJbITOdunwCLgUWVfOLgEua9JkErKk+J1bzE+vWvwv4HnBnp8dTeszAeOD4qs9rgFuBuZ0e02bGuStwH/DGqtZfAzMb+nwM+EY1fzpwdTU/s+q/GzC92s+unR5T4TEfCuxXzR8ErO30eEqOt279tcD/Bj7V6fFsz+QRTG+YD1xRzV8BnNqkz8nAssx8IjOfBJYBcwAiYg/gk8DnypfaMiMec2Y+k5k3A2Tm88BKoK98ySNyJLA6M9dUtV5Fbez16v9bXAucEBFRtV+Vmc9l5v3A6mp/3W7EY87MX2Xmuqp9FbB7ROzWlqpHbjS/YyLiVOB+auPtKQZMb9gnMx+q5h8G9mnSZ3/gwbrl4aoN4CLgC8AzxSpsvdGOGYCI2As4BbipQI2tsNUx1PfJzBeADcDkbdy2G41mzPXeDazMzOcK1dkqIx5v9cfhWcAFbaiz5cZ0ugDVRMSNwOuarDqnfiEzMyK2+d7yiDgEeFNm/m3jed1OKzXmuv2PAa4ELsvMNSOrUt0oImYBlwAndbqWws4HvpSZT1cHND3FgOkSmXni5tZFxCMRsW9mPhQR+wKPNum2FjiubrkPWA4cAwxExAPUft97R8TyzDyODis45k0WA0OZ+eXRV1vMWuD1dct9VVuzPsNVaE4A1m/jtt1oNGMmIvqAHwAfzMz7ypc7aqMZ71HAeyLiUmAv4KWI2JiZXyledSt0+iKQ09Yn4O955QXvS5v0mUTtPO3EarofmNTQp5/eucg/qjFTu970fWCXTo9lK+McQ+3mhOn86QLwrIY+H+eVF4CvqeZn8cqL/GvojYv8oxnzXlX/d3V6HO0Yb0Of8+mxi/wdL8BpG35JtXPPNwFDwI11/4gOAN+q6/eX1C70rgY+1GQ/vRQwIx4ztb8QE7gbuKOa/qrTY9rCWN8O/JbanUbnVG0XAvOq+XHU7iBaDfwSeGPdtudU291Ll94p18oxA58B/lD3e70D2LvT4yn5O67bR88FjI+KkSQV4V1kkqQiDBhJUhEGjCSpCANGklSEASNJKsKAkXYSEbG8+sKt1BYGjDQKEXFcROQWphc6XaPUKT4qRmqNK4GlTdpfanchUrcwYKTWWJmZ3+10EVI38RSZ1AYR0V+dMjs/It4XEf8cERsj4l+rtlf9sRcRfxYRP4iI9VXfuyLi0xGxa5O+r4uIyyJiTUQ8FxGPVm8Cnd2k734RcWVEPBkRz0TE9RHxb0uNXTsvj2Ck1hgfEVOatD+fmb+rW55H7c2GX6X2npt5wHnAG4APbeoUEQPAT4E/1vU9hdoj6t8KfKCubz/wM2rvzPlHYBB4LXA0cCK1F7Ft8lrgFuDnwH+j9gDGvwF+GBEHZeaLIxq91EynH4bm5NTLE7XXBeQWpv9T9euvll8EDqvbPqg9ej6Bo+vafwa8APxZQ99rqr4n1LUvrdpOblLfLnXzy6t+n27oc+bmtndyGs3kKTKpNRYDs5tM5zT0W5aZKzctZGYCl1aL7wSIiL2BPweWZOY/N/T9u4a+k6i9Gvv/Zub1jUVlZuNNBi8BlzW0/aT6PHCro5S2g6fIpNYYyswbt6Hf3U3a7qo+31h9Tq8+m72D/W5qIbGp7wHUjmx+tY11rsvMjQ1t66vPxlcSS6PiEYy0c9nSNZbeeyevupoBI7XXjCZtM6vPNdXn/dXnrCZ930Lt/9tNfVdTu35ySIvqk1rGgJHaa3ZEHLZpISIC+HS1+E8Amfko8P+AUyLioIa+Z1eLP6j6PgH8GJgbESc2/rBqG6kjvAYjtcZhEXHGZtb9U938r4GfRMRXgYeA+dRuJf5OZt5W1+9vqN2mfGvV92HgPwAnA9/LzJvq+n6CWiD9OCKuAFYAuwNHAQ8AZ41uaNLIGDBSa7yvmpo5kNotxwBLgHupHYm8GXgUuKiaXpaZgxHx58AFwMeofX9lDbWw+EJD3/ur7818ltq73z8IPEktzBaPdmDSSEXtzkdJJVVfhrwfuCAzz+9sNVJ7eA1GklSEASNJKsKAkSQV4TUYSVIRHsFIkoowYCRJRRgwkqQiDBhJUhEGjCSpiP8PUKkf2+M6ZjoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.plot(test_loss_list)\n",
    "plt.plot(train_loss_list)\n",
    "plt.legend([\"test\",\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM2, self).__init__()\n",
    "        self.lstm_layer = nn.LSTM(input_size=768, hidden_size=512, batch_first=True)\n",
    "        self.linear_layer = nn.Linear(in_features=512, out_features=256, bias=True)\n",
    "        self.linear_layer2 = nn.Linear(in_features=256, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, (h_n, h_c) = self.lstm_layer(x)\n",
    "        a, b, c = h_n.shape\n",
    "        out = self.linear_layer(h_n.reshape(a * b, c))\n",
    "        out = self.linear_layer2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.674 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9574\n",
      "4988\n",
      "4586\n",
      "训练集有8616个数据\n",
      "测试集有958个数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train Loss: 0| Test Loss: 0:   0%|          | 0/431 [00:00<?, ?it/s]/app/common/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "Epoch: 0| Train Loss: 0| Test Loss: 0: 100%|██████████| 431/431 [02:38<00:00,  2.72it/s]\n",
      "Epoch: 1| Train Loss: 0.007235404177817001| Test Loss: 0.16754387196684686: 100%|██████████| 431/431 [04:02<00:00,  1.78it/s]\n",
      "Epoch: 2| Train Loss: 0.02632076990841716| Test Loss: 0.15709324616277007: 100%|██████████| 431/431 [03:36<00:00,  1.99it/s]\n",
      "Epoch: 3| Train Loss: 0.012746736046362363| Test Loss: 0.1280096331413239: 100%|██████████| 431/431 [03:16<00:00,  2.19it/s]\n",
      "Epoch: 4| Train Loss: 0.012353127845964153| Test Loss: 0.11382797186532782: 100%|██████████| 431/431 [02:53<00:00,  2.49it/s]\n",
      "Epoch: 5| Train Loss: 0.01104646265366991| Test Loss: 0.116217832802699: 100%|██████████| 431/431 [04:28<00:00,  1.60it/s]\n",
      "Epoch: 6| Train Loss: 0.009990759771012409| Test Loss: 0.1203454742184534: 100%|██████████| 431/431 [15:27<00:00,  2.15s/it]  \n",
      "Epoch: 7| Train Loss: 0.012356945397883812| Test Loss: 0.11099641003124863: 100%|██████████| 431/431 [03:29<00:00,  2.06it/s]\n",
      "Epoch: 8| Train Loss: 0.013015015222018827| Test Loss: 0.10204294075205826: 100%|██████████| 431/431 [03:29<00:00,  2.06it/s]\n",
      "Epoch: 9| Train Loss: 0.011924098238758583| Test Loss: 0.10214972146568395: 100%|██████████| 431/431 [03:39<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5208768267223383\n"
     ]
    }
   ],
   "source": [
    "seed_torch(22)\n",
    "epoch = 10\n",
    "batch_size = 20\n",
    "early_stop = 5\n",
    "test_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "# 初始化模型\n",
    "model = LSTM2()\n",
    "model_ = LSTM2()\n",
    "\n",
    "# 数据处理部分\n",
    "gd = GetData()\n",
    "x, y = gd.split_sen()\n",
    "pos = y.count(1)\n",
    "neg = y.count(0)\n",
    "pos_train = int(pos*0.9)\n",
    "neg_train = int(neg*0.9)\n",
    "x1 = x[:pos]  # 3988   --- 3589train 399test\n",
    "y1 = y[:pos]\n",
    "x0 = x[pos:]  # 3589   ---- 3230train 359test\n",
    "y0 = y[pos:]\n",
    "\n",
    "train_x = x0[:neg_train] + x1[:pos_train]\n",
    "train_y = y0[:neg_train] + y1[:pos_train]\n",
    "print(\"训练集有\"+str(len(train_x))+\"个数据\")\n",
    "\n",
    "# c = list(zip(train_x, train_y))\n",
    "# random.shuffle(c)\n",
    "# c = random.sample(c, 50)\n",
    "# train_x[:], train_y[:] = zip(*c)\n",
    "\n",
    "test_x = x0[neg_train:] + x1[pos_train:]\n",
    "test_y = y0[neg_train:] + y1[pos_train:]\n",
    "print(\"测试集有\"+str(len(test_x))+\"个数据\")\n",
    "\n",
    "bert = GetBERT()\n",
    "x_train = bert(train_x)\n",
    "x_test = bert(test_x)\n",
    "y_train = torch.tensor(train_y).float()\n",
    "y_test = torch.tensor(test_y).float()\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_dataLoader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_dataLoader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(epoch, train_dataLoader, test_dataLoader)\n",
    "p, y, test_loss, test_loss_list = test_model(test_dataLoader)\n",
    "ans = []\n",
    "for t in p:\n",
    "    if t[0]>t[1]:\n",
    "        ans.append(0)\n",
    "    else:\n",
    "        ans.append(1)\n",
    "print(accuracy_score(ans,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3b3c64f3a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.plot(test_loss_list)\n",
    "plt.plot(train_loss_list)\n",
    "plt.legend([\"test\",\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双向GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(torch.nn.Module):\n",
    "    def __init__(self, input_dim=768,hidden_size=768, out_size=2, n_layers=1, batch_size=1):\n",
    "        super(BiGRU, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.out_size = out_size\n",
    "        self.gru = torch.nn.GRU(input_dim, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
    "        self.fc1 = torch.nn.Linear(hidden_size*2, 300)\n",
    "        self.fc2 = torch.nn.Linear(300, out_size)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "       # hidden 就是上下文输出，output 就是 RNN 输出\n",
    "        output, hidden = self.gru(word_inputs, hidden)\n",
    "        # output是所有隐藏层的状态，hidden是最后一层隐藏层的状态\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "\n",
    "        # 仅仅获取 time seq 维度中的最后一个向量\n",
    "        # the last of time_seq\n",
    "        output = output[:,-1,:]\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.autograd.Variable(torch.zeros(2*self.n_layers, self.batch_size, self.hidden_size, device='cuda'))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "10\n",
      "10\n",
      "训练集有18个数据\n",
      "测试集有2个数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train Loss: 0| Test Loss: 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a7cae41a9631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-893055b7fcdd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epoch, train_dataLoader, test_dataLoader)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#for x, y in train_dataLoader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mx_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/common/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'hidden'"
     ]
    }
   ],
   "source": [
    "seed_torch(22)\n",
    "epoch = 10\n",
    "batch_size = 20\n",
    "early_stop = 5\n",
    "test_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "# 初始化模型\n",
    "model = BiGRU()\n",
    "model_ = BiGRU()\n",
    "\n",
    "# 数据处理部分\n",
    "gd = GetData(pos=10, neg=10)\n",
    "x, y = gd.split_sen()\n",
    "pos = y.count(1)\n",
    "neg = y.count(0)\n",
    "pos_train = int(pos*0.9)\n",
    "neg_train = int(neg*0.9)\n",
    "x1 = x[:pos]  # 3988   --- 3589train 399test\n",
    "y1 = y[:pos]\n",
    "x0 = x[pos:]  # 3589   ---- 3230train 359test\n",
    "y0 = y[pos:]\n",
    "\n",
    "train_x = x0[:neg_train] + x1[:pos_train]\n",
    "train_y = y0[:neg_train] + y1[:pos_train]\n",
    "print(\"训练集有\"+str(len(train_x))+\"个数据\")\n",
    "\n",
    "# c = list(zip(train_x, train_y))\n",
    "# random.shuffle(c)\n",
    "# c = random.sample(c, 50)\n",
    "# train_x[:], train_y[:] = zip(*c)\n",
    "\n",
    "test_x = x0[neg_train:] + x1[pos_train:]\n",
    "test_y = y0[neg_train:] + y1[pos_train:]\n",
    "print(\"测试集有\"+str(len(test_x))+\"个数据\")\n",
    "\n",
    "bert = GetBERT()\n",
    "x_train = bert(train_x)\n",
    "x_test = bert(test_x)\n",
    "y_train = torch.tensor(train_y).float()\n",
    "y_test = torch.tensor(test_y).float()\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_dataLoader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_dataLoader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(epoch, train_dataLoader, test_dataLoader)\n",
    "p, y, test_loss, test_loss_list = test_model(test_dataLoader)\n",
    "ans = []\n",
    "for t in p:\n",
    "    if t[0]>t[1]:\n",
    "        ans.append(0)\n",
    "    else:\n",
    "        ans.append(1)\n",
    "print(accuracy_score(ans,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
